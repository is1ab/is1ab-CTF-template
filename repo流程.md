## ğŸ“‹ ä¸‰éšæ®µæµç¨‹æ¦‚è¦½

```
éšæ®µ 1: é–‹ç™¼æº–å‚™                éšæ®µ 2: é¡Œç›®é–‹ç™¼              éšæ®µ 3: å…¬é–‹ç™¼å¸ƒ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Template Repo  â”‚ Fork        â”‚  Private Repo   â”‚ æ¯”è³½å¾Œ    â”‚  Public Repo    â”‚
â”‚   (is1ab-org)   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   (is1ab-org)   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   (is1ab-org)   â”‚
â”‚     Public      â”‚             â”‚     Private     â”‚           â”‚     Public      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â–²                             â”‚
                                         â”‚ PR                          â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â–¼
                                â”‚  Personal Fork  â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚   (å€‹äººå¸³è™Ÿ)      â”‚           â”‚  GitHub Pages   â”‚
                                â”‚     Private     â”‚           â”‚   éœæ…‹ç¶²ç«™å±•ç¤º    â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ éšæ®µ 1: é–‹ç™¼æº–å‚™

### 1.1 çµ„ç¹”è¨­ç½® Template

```bash
# çµ„ç¹”ç®¡ç†å“¡æ“ä½œ
# 1. åœ¨ GitHub ä¸Šä½¿ç”¨ is1ab-CTF-template å‰µå»ºæ–° repo
# Repository name: 2024-is1ab-CTF-template
# Visibility: Public (ä½œç‚ºæ¨¡æ¿ä½¿ç”¨)

# 2. å•Ÿç”¨ Template åŠŸèƒ½
# Settings â†’ General â†’ Template repository âœ…
```

### 1.2 å»ºç«‹ Private é–‹ç™¼ Repo

```bash
# çµ„ç¹”ç®¡ç†å“¡æ“ä½œ
# 1. ä½¿ç”¨ Template å‰µå»ºç§æœ‰å€‰åº«
# Repository name: 2024-is1ab-CTF
# Visibility: Private
# Include all branches: âœ…

# 2. è¨­ç½® Repository æ¬Šé™
# Settings â†’ Manage access
# - Admin: æ ¸å¿ƒåœ˜éšŠ (3-5äºº)
# - Write: é¡Œç›®é–‹ç™¼è€… (10-20äºº)
# - Read: å¯©æŸ¥è€…

# 3. è¨­ç½®åˆ†æ”¯ä¿è­·
# Settings â†’ Branches â†’ Add protection rule
# Branch: main
# âœ… Require pull request reviews (è‡³å°‘1äºº)
# âœ… Require status checks to pass
# âœ… Require branches to be up to date
# âœ… Include administrators
```

### 1.3 é…ç½®è‡ªå‹•åŒ–

```yaml
# .github/workflows/validate-pr.yml
name: ğŸ” Validate Pull Request

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'challenges/**'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: ğŸ Setup Python with uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "requirements.txt"
      
      - name: ğŸ“¦ Install dependencies
        run: |
          uv venv
          uv pip install -r requirements.txt
      
      - name: ğŸ” Validate new challenges
        run: |
          # ç²å– PR è®Šæ›´çš„é¡Œç›®
          git fetch origin main
          CHANGED_DIRS=$(git diff --name-only origin/main...HEAD | grep "challenges/" | cut -d'/' -f1-3 | sort -u)
          
          for dir in $CHANGED_DIRS; do
            if [ -d "$dir" ]; then
              echo "Validating $dir"
              uv run scripts/validate-challenge.py "$dir"
            fi
          done
      
      #- name: ğŸ”’ Check sensitive data
      
      - name: ğŸ³ Test Docker builds
        run: |
          CHANGED_DIRS=$(git diff --name-only origin/main...HEAD | grep "challenges/" | cut -d'/' -f1-3 | sort -u)
          for dir in $CHANGED_DIRS; do
            if [ -f "$dir/docker/Dockerfile" ]; then
              echo "Testing Docker build for $dir"
              cd "$dir/docker"
              docker build -t test-build .
              cd - > /dev/null
            fi
          done
```

## ğŸ› ï¸ éšæ®µ 2: é¡Œç›®é–‹ç™¼

### 2.1 å€‹äºº Fork æµç¨‹

```bash
# é¡Œç›®é–‹ç™¼è€…æ“ä½œ

# 1. Fork çµ„ç¹”çš„ private repo åˆ°å€‹äººå¸³è™Ÿ
# åœ¨ GitHub ä¸Šé»æ“Š Fork æŒ‰éˆ•
# âš ï¸ ç¢ºèª Fork ä¹Ÿæ˜¯ Private

# 2. Clone å€‹äºº Fork
git clone https://github.com/YOUR-USERNAME/2024-is1ab-CTF.git
cd 2024-is1ab-CTF

# 3. è¨­ç½® upstream
git remote add upstream https://github.com/is1ab-org/2024-is1ab-CTF.git

# 4. åŒæ­¥æœ€æ–°ä»£ç¢¼
git fetch upstream
git checkout main
git merge upstream/main
git push origin main
```

### 2.2 é¡Œç›®é–‹ç™¼æµç¨‹

```bash
# 1. å‰µå»ºé¡Œç›®åˆ†æ”¯
uv run scripts/create-challenge.py web my_challenge middle --author YourName
# è‡ªå‹•å‰µå»ºåˆ†æ”¯: challenge/web/my_challenge

# 2. é–‹ç™¼é¡Œç›®å…§å®¹
# ç·¨è¼¯ challenges/web/my_challenge/ ä¸‹çš„æª”æ¡ˆï¼š
# - public.yml: åŸºæœ¬è³‡è¨Šé…ç½®
# - src/: é¡Œç›®æºç¢¼
# - docker/: å®¹å™¨é…ç½®
# - writeup/: å®˜æ–¹è§£ç­”
# - files/: æä¾›çµ¦åƒè³½è€…çš„æª”æ¡ˆ

# 3. æœ¬åœ°æ¸¬è©¦
cd challenges/web/my_challenge/docker/
docker-compose up -d
# æ¸¬è©¦é¡Œç›®åŠŸèƒ½
docker-compose down

# 4. é©—è­‰é¡Œç›®
uv run scripts/validate-challenge.py challenges/web/my_challenge/

# 5. æäº¤è®Šæ›´
git add challenges/web/my_challenge/
git commit -m "feat(web): add my_challenge - SQL injection basics"
git push origin challenge/web/my_challenge
```

### 2.3 PR æäº¤èˆ‡å¯©æŸ¥

```bash
# 1. åœ¨ GitHub ä¸Šå‰µå»º Pull Request
# From: your-username:challenge/web/my_challenge
# To: is1ab-org:main

# 2. å¡«å¯« PR æ¨¡æ¿
Title: feat(web): add my_challenge - SQL injection basics

## ğŸ“‹ è®Šæ›´å…§å®¹
- [x] æ–°å¢é¡Œç›®
- [ ] ä¿®å¾©å•é¡Œ
- [ ] æ›´æ–°æ–‡æª”

## ğŸ¯ é¡Œç›®è³‡è¨Š
**é¡Œç›®åç¨±**: My Challenge
**åˆ†é¡**: Web
**é›£åº¦**: middle  
**ä¼°è¨ˆåˆ†æ•¸**: 200
**æ˜¯å¦éœ€è¦éƒ¨ç½²**: Yes

## ğŸ“ è®Šæ›´èªªæ˜
æ–°å¢ä¸€å€‹ä¸­ç­‰é›£åº¦çš„ SQL æ³¨å…¥é¡Œç›®ï¼Œé©åˆåˆå­¸è€…å­¸ç¿’åŸºæœ¬çš„æ³¨å…¥æŠ€å·§ã€‚

## âœ… æª¢æŸ¥æ¸…å–®
- [x] æœ¬åœ°æ¸¬è©¦é€šé
- [x] Docker å»ºæ§‹æˆåŠŸ
- [x] è§£é¡Œæµç¨‹é©—è­‰
- [x] Writeup å·²å®Œæˆ
- [x] æ•æ„Ÿè³‡æ–™æª¢æŸ¥
```

### 2.4 è‡ªå‹•åŒ–å¯©æŸ¥æµç¨‹

```yaml
# .github/CODEOWNERS
# è‡ªå‹•åˆ†é…å¯©æŸ¥è€…
challenges/web/**     @web-security-team @senior-reviewer
challenges/pwn/**     @binary-team @senior-reviewer  
challenges/crypto/**  @crypto-team @senior-reviewer
challenges/reverse/** @reverse-team @senior-reviewer
challenges/forensic/** @forensic-team @senior-reviewer
challenges/misc/**    @misc-team @senior-reviewer

# å…¨å±€å¯©æŸ¥è€…
* @admin @lead-developer
```

### 2.5 é€²åº¦è¿½è¹¤ç³»çµ±

```bash
# æ¯æ¬¡ PR åˆä½µå¾Œè‡ªå‹•æ›´æ–°
# .github/workflows/update-progress.yml 
name: ğŸ“Š Update Progress

on:
  push:
    branches: [main]
  pull_request:
    types: [closed]
    branches: [main]

jobs:
  update:
    if: github.event.pull_request.merged == true || github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: ğŸ“Š Update README
        run: uv run scripts/update-readme.py
      - name: ğŸ’¾ Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: 'ğŸ¤– Auto-update progress [skip ci]'
```

## ğŸŒ éšæ®µ 3: å…¬é–‹ç™¼å¸ƒ

### 3.1 æ¯”è³½çµæŸå¾Œçš„ç™¼å¸ƒæµç¨‹

```bash
# çµ„ç¹”ç®¡ç†å“¡æ“ä½œ

# 1. å‰µå»º Public Repository
# Repository name: 2024-is1ab-CTF-public
# Visibility: Public
# Description: IS1AB CTF 2024 - Challenge Archive & Results

# 2. æº–å‚™å…¬é–‹å…§å®¹
uv run scripts/prepare-public-release.py --event-date 2024-12-15

# 3. åŒæ­¥å…§å®¹åˆ° Public Repo
uv run scripts/sync-to-public.py --target-repo is1ab-org/2024-is1ab-CTF-public
```

### 3.2 å…¬é–‹ç™¼å¸ƒè…³æœ¬

```python
#!/usr/bin/env python3
# scripts/prepare-public-release.py

import shutil
import yaml
from pathlib import Path
import argparse
from datetime import datetime

def prepare_public_release(event_date):
    """æº–å‚™å…¬é–‹ç™¼å¸ƒçš„å…§å®¹"""
    
    # å‰µå»º public ç›®éŒ„
    public_dir = Path('public-release')
    public_dir.mkdir(exist_ok=True)
    
    # 1. è¤‡è£½å®‰å…¨å…§å®¹
    safe_files = [
        'README.md',
        'docs/',
        'templates/',
        '.github/',
        'requirements.txt',
        'LICENSE'
    ]
    
    for file_path in safe_files:
        src = Path(file_path)
        if src.exists():
            if src.is_dir():
                shutil.copytree(src, public_dir / src.name, dirs_exist_ok=True)
            else:
                shutil.copy2(src, public_dir / src.name)
    
    # 2. è™•ç†é¡Œç›®å…§å®¹
    challenges_dir = Path('challenges')
    public_challenges_dir = public_dir / 'challenges'
    
    for category_dir in challenges_dir.iterdir():
        if not category_dir.is_dir():
            continue
            
        public_category_dir = public_challenges_dir / category_dir.name
        public_category_dir.mkdir(parents=True, exist_ok=True)
        
        for challenge_dir in category_dir.iterdir():
            if not challenge_dir.is_dir():
                continue
                
            public_challenge_dir = public_category_dir / challenge_dir.name
            public_challenge_dir.mkdir(exist_ok=True)
            
            # è¤‡è£½å…¬é–‹æª”æ¡ˆ
            safe_challenge_files = [
                'README.md',
                'files/',  # æä¾›çµ¦åƒè³½è€…çš„æª”æ¡ˆ
                'writeup/',  # æ¯”è³½çµæŸå¾Œå¯ä»¥å…¬é–‹
            ]
            
            for file_name in safe_challenge_files:
                src_file = challenge_dir / file_name
                if src_file.exists():
                    if src_file.is_dir():
                        shutil.copytree(src_file, public_challenge_dir / file_name, dirs_exist_ok=True)
                    else:
                        shutil.copy2(src_file, public_challenge_dir / file_name)
            
            # å‰µå»ºå…¬é–‹ç‰ˆæœ¬çš„ public.yml
            public_yml = challenge_dir / 'public.yml'
            if public_yml.exists():
                with open(public_yml, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)
                
                # ç§»é™¤æ•æ„Ÿè³‡è¨Šï¼Œæ·»åŠ æ¯”è³½çµæœ
                public_data = {
                    'title': data.get('title'),
                    'author': data.get('author'),
                    'difficulty': data.get('difficulty'),
                    'category': data.get('category'),
                    'description': data.get('description'),
                    'points': data.get('points'),
                    'tags': data.get('tags', []),
                    'event_info': {
                        'event_date': event_date,
                        'status': 'archived',
                        'published_at': datetime.now().isoformat()
                    }
                }
                
                with open(public_challenge_dir / 'public.yml', 'w', encoding='utf-8') as f:
                    yaml.dump(public_data, f, default_flow_style=False, allow_unicode=True)
    
    # 3. ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    generate_event_report(public_dir, event_date)
    
    print(f"âœ… Public release prepared in {public_dir}")

def generate_event_report(public_dir, event_date):
    """ç”Ÿæˆæ¯”è³½å ±å‘Š"""
    report_content = f"""# IS1AB CTF {event_date[:4]} - Event Report

## ğŸ“Š Competition Overview

- **Date**: {event_date}
- **Duration**: 8 hours
- **Participants**: XX teams
- **Challenges**: XX total

## ğŸ† Results Summary

### Top 10 Teams
1. Team Alpha - 2500 pts
2. Team Beta - 2300 pts
3. Team Gamma - 2100 pts
... (æ¯”è³½çµæŸå¾Œå¡«å…¥çœŸå¯¦çµæœ)

## ğŸ“ˆ Challenge Statistics

### Solve Rates by Category
- Web: XX% average solve rate
- Pwn: XX% average solve rate
- Crypto: XX% average solve rate
- Reverse: XX% average solve rate
- Forensics: XX% average solve rate
- Misc: XX% average solve rate

## ğŸ“ Educational Impact

This CTF was designed to provide hands-on experience with:
- Real-world security vulnerabilities
- Modern exploitation techniques
- Defensive security practices
- Collaborative problem-solving

## ğŸ“ Writeups Available

All official writeups are now available in the respective challenge directories.

## ğŸ”— Resources

- [Challenge Archive](./challenges/)
- [Docker Compose Files](./docker/)
- [Setup Instructions](./docs/)

---
*Archive created on {datetime.now().strftime('%Y-%m-%d')}*
"""
    
    with open(public_dir / 'EVENT_REPORT.md', 'w', encoding='utf-8') as f:
        f.write(report_content)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Prepare public release')
    parser.add_argument('--event-date', required=True, help='Event date (YYYY-MM-DD)')
    args = parser.parse_args()
    
    prepare_public_release(args.event_date)
```

### 3.3 GitHub Pages è¨­ç½®

```yaml
# .github/workflows/deploy-pages.yml (åœ¨ public repo ä¸­)
name: ğŸŒ Deploy Pages

on:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Pages
        uses: actions/configure-pages@v4
      
      - name: Build site
        run: |
          mkdir -p _site
          uv run scripts/build-archive-site.py
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '_site'
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```

## ğŸ”§ å·¥å…·å’Œè…³æœ¬æ›´æ–°

### å€‹äºº Fork åŒæ­¥è…³æœ¬

```bash
#!/bin/bash
# scripts/sync-fork.sh

echo "ğŸ”„ Syncing personal fork with upstream..."

# ç²å–æœ€æ–°çš„ upstream è®Šæ›´
git fetch upstream

# åˆ‡æ›åˆ° main åˆ†æ”¯
git checkout main

# åˆä½µ upstream è®Šæ›´
git merge upstream/main

# æ¨é€åˆ°å€‹äºº fork
git push origin main

echo "âœ… Sync completed!"

# æ¸…ç†å·²åˆä½µçš„åˆ†æ”¯
echo "ğŸ§¹ Cleaning up merged branches..."
git branch --merged | grep -v "main" | xargs -n 1 git branch -d

echo "ğŸ‰ All done!"
```

### PR æ¨¡æ¿æ›´æ–°

```markdown
<!-- .github/PULL_REQUEST_TEMPLATE.md -->
## ğŸ“‹ è®Šæ›´é¡å‹
- [ ] ğŸ†• æ–°å¢é¡Œç›®
- [ ] ğŸ› ä¿®å¾©å•é¡Œ  
- [ ] ğŸ“š æ›´æ–°æ–‡æª”
- [ ] â™»ï¸ ç¨‹å¼ç¢¼é‡æ§‹
- [ ] ğŸ”§ å·¥å…·æ”¹é€²

## ğŸ¯ é¡Œç›®è³‡è¨Š (å¦‚é©ç”¨)
**é¡Œç›®åç¨±**: 
**åˆ†é¡**: [ Web | Pwn | Crypto | Reverse | Forensics | Misc ]
**é›£åº¦**: [ baby | easy | middle | hard | impossible ]
**ä¼°è¨ˆåˆ†æ•¸**: 
**éƒ¨ç½²éœ€æ±‚**: [ éœæ…‹é™„ä»¶ | éœæ…‹å®¹å™¨ | å‹•æ…‹é™„ä»¶ | å‹•æ…‹å®¹å™¨ ]

## ğŸ“ è®Šæ›´èªªæ˜
[æ¸…æ¥šæè¿°é€™æ¬¡è®Šæ›´çš„å…§å®¹å’ŒåŸå› ]

## ğŸ§ª æ¸¬è©¦æª¢æŸ¥æ¸…å–®
- [ ] æœ¬åœ°åŠŸèƒ½æ¸¬è©¦é€šé
- [ ] Docker å»ºæ§‹æˆåŠŸ
- [ ] é¡Œç›®å¯æ­£å¸¸è§£é¡Œ
- [ ] Writeup é©—è­‰å®Œæˆ
- [ ] ç„¡æ•æ„Ÿè³‡æ–™æ´©éœ²
- [ ] ç¬¦åˆç¨‹å¼ç¢¼è¦ç¯„

## ğŸ”— ç›¸é—œ Issue
Closes #(issue number)

## ğŸ“· æˆªåœ– (å¦‚é©ç”¨)
[å¦‚æœæœ‰ UI è®Šæ›´æˆ–æ–°åŠŸèƒ½ï¼Œè«‹æä¾›æˆªåœ–]

## ğŸ’­ é¡å¤–èªªæ˜
[ä»»ä½•éœ€è¦å¯©æŸ¥è€…ç‰¹åˆ¥æ³¨æ„çš„åœ°æ–¹]

---
### ğŸ“‹ å¯©æŸ¥è€…æª¢æŸ¥æ¸…å–®
- [ ] ç¨‹å¼ç¢¼å“è³ªç¬¦åˆæ¨™æº–
- [ ] é¡Œç›®è¨­è¨ˆåˆç†ä¸”æœ‰è¶£
- [ ] å®‰å…¨æ€§æª¢æŸ¥é€šé
- [ ] æ–‡æª”å®Œæ•´ä¸”æ¸…æ¥š
- [ ] æ¸¬è©¦è¦†è“‹å……åˆ†
```

## ğŸ“ˆ æµç¨‹ç›£æ§å’Œçµ±è¨ˆ

### Dashboard è…³æœ¬

```python
#!/usr/bin/env python3
# scripts/generate-dashboard.py

import json
import subprocess
import yaml
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict

def generate_development_dashboard():
    """ç”Ÿæˆé–‹ç™¼å„€è¡¨æ¿"""
    
    dashboard_data = {
        'generated_at': datetime.now().isoformat(),
        'pr_stats': get_pr_statistics(),
        'challenge_progress': get_challenge_progress(),
        'contributor_stats': get_contributor_statistics(),
        'timeline': get_development_timeline(),
        'quality_metrics': get_quality_metrics(),
        'deployment_status': get_deployment_status()
    }
    
    # ç”Ÿæˆ HTML å„€è¡¨æ¿
    generate_html_dashboard(dashboard_data)
    
    # ç”Ÿæˆ JSON æ•¸æ“š
    with open('dashboard.json', 'w', encoding='utf-8') as f:
        json.dump(dashboard_data, f, indent=2, ensure_ascii=False)
    
    return dashboard_data

def get_pr_statistics():
    """ç²å– PR çµ±è¨ˆ"""
    try:
        # ä½¿ç”¨ GitHub CLI ç²å– PR çµ±è¨ˆ
        cmd = ['gh', 'pr', 'list', '--json', 'state,author,createdAt,title,labels']
        result = subprocess.run(cmd, capture_output=True, text=True)
        prs = json.loads(result.stdout)
        
        stats = {
            'total': len(prs),
            'open': len([pr for pr in prs if pr['state'] == 'OPEN']),
            'merged': len([pr for pr in prs if pr['state'] == 'MERGED']),
            'closed': len([pr for pr in prs if pr['state'] == 'CLOSED']),
            'by_author': defaultdict(int),
            'recent_activity': []
        }
        
        for pr in prs:
            stats['by_author'][pr['author']['login']] += 1
            if datetime.fromisoformat(pr['createdAt'].replace('Z', '+00:00')) > datetime.now() - timedelta(days=7):
                stats['recent_activity'].append({
                    'title': pr['title'],
                    'author': pr['author']['login'],
                    'date': pr['createdAt']
                })
        
        return stats
    except:
        return {'error': 'Unable to fetch PR statistics'}

def get_challenge_progress():
    """ç²å–é¡Œç›®é€²åº¦çµ±è¨ˆ"""
    challenges_dir = Path('challenges')
    progress = {
        'total_challenges': 0,
        'by_category': defaultdict(int),
        'by_difficulty': defaultdict(int),
        'by_status': defaultdict(int),
        'by_type': defaultdict(int),
        'completion_rate': 0
    }
    
    if not challenges_dir.exists():
        return progress
    
    for category_dir in challenges_dir.iterdir():
        if not category_dir.is_dir():
            continue
            
        for challenge_dir in category_dir.iterdir():
            if not challenge_dir.is_dir():
                continue
                
            public_yml = challenge_dir / 'public.yml'
            if public_yml.exists():
                with open(public_yml, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)
                
                progress['total_challenges'] += 1
                progress['by_category'][data.get('category', 'unknown')] += 1
                progress['by_difficulty'][data.get('difficulty', 'unknown')] += 1
                progress['by_status'][data.get('status', 'planning')] += 1
                progress['by_type'][data.get('challenge_type', 'static_attachment')] += 1
    
    # è¨ˆç®—å®Œæˆç‡
    completed = progress['by_status']['completed'] + progress['by_status']['deployed']
    if progress['total_challenges'] > 0:
        progress['completion_rate'] = round((completed / progress['total_challenges']) * 100, 1)
    
    return progress

def get_contributor_statistics():
    """ç²å–è²¢ç»è€…çµ±è¨ˆ"""
    try:
        # ç²å–æœ€è¿‘30å¤©çš„æäº¤çµ±è¨ˆ
        cmd = ['git', 'log', '--since=30.days.ago', '--pretty=format:%an|%ad|%s', '--date=short']
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())
        
        contributors = defaultdict(lambda: {'commits': 0, 'last_commit': None})
        
        for line in result.stdout.strip().split('\n'):
            if '|' in line:
                parts = line.split('|', 2)
                author = parts[0]
                date = parts[1]
                
                contributors[author]['commits'] += 1
                if not contributors[author]['last_commit'] or date > contributors[author]['last_commit']:
                    contributors[author]['last_commit'] = date
        
        return dict(contributors)
    except:
        return {'error': 'Unable to fetch contributor statistics'}

def get_development_timeline():
    """ç²å–é–‹ç™¼æ™‚ç¨‹è¡¨"""
    timeline = {
        'milestones': [
            {
                'name': 'é¡Œç›®é–‹ç™¼éšæ®µ',
                'start_date': '2024-10-01',
                'end_date': '2024-11-15',
                'status': 'in_progress',
                'progress': 65
            },
            {
                'name': 'æ¸¬è©¦èˆ‡é©—è­‰',
                'start_date': '2024-11-16',
                'end_date': '2024-11-30',
                'status': 'planned',
                'progress': 0
            },
            {
                'name': 'å¹³å°éƒ¨ç½²',
                'start_date': '2024-12-01',
                'end_date': '2024-12-10',
                'status': 'planned',
                'progress': 0
            },
            {
                'name': 'CTF æ¯”è³½',
                'start_date': '2024-12-15',
                'end_date': '2024-12-15',
                'status': 'planned',
                'progress': 0
            }
        ],
        'upcoming_deadlines': [
            {
                'task': 'å®Œæˆæ‰€æœ‰ Web é¡Œç›®',
                'deadline': '2024-11-01',
                'responsible': 'web-team'
            },
            {
                'task': 'å®Œæˆæ‰€æœ‰ PWN é¡Œç›®',
                'deadline': '2024-11-05',
                'responsible': 'pwn-team'
            }
        ]
    }
    
    return timeline

def get_quality_metrics():
    """ç²å–å“è³ªæŒ‡æ¨™"""
    metrics = {
        'code_coverage': 0,
        'test_pass_rate': 0,
        'security_issues': 0,
        'documentation_coverage': 0,
        'automated_tests': 0
    }
    
    # æª¢æŸ¥æ¸¬è©¦è¦†è“‹ç‡
    try:
        # å¦‚æœæœ‰æ¸¬è©¦ï¼Œé‹è¡Œä¸¦ç²å–è¦†è“‹ç‡
        test_files = list(Path('.').glob('tests/**/*.py'))
        metrics['automated_tests'] = len(test_files)
    except:
        pass
    
    # æª¢æŸ¥æ–‡æª”è¦†è“‹ç‡
    challenges_dir = Path('challenges')
    if challenges_dir.exists():
        total_challenges = 0
        documented_challenges = 0
        
        for category_dir in challenges_dir.iterdir():
            if not category_dir.is_dir():
                continue
            for challenge_dir in category_dir.iterdir():
                if not challenge_dir.is_dir():
                    continue
                total_challenges += 1
                if (challenge_dir / 'README.md').exists():
                    documented_challenges += 1
        
        if total_challenges > 0:
            metrics['documentation_coverage'] = round((documented_challenges / total_challenges) * 100, 1)
    
    return metrics

def get_deployment_status():
    """ç²å–éƒ¨ç½²ç‹€æ…‹"""
    status = {
        'platform_ready': False,
        'docker_registry': 'pending',
        'monitoring_setup': False,
        'backup_configured': False,
        'ssl_certificates': False,
        'load_balancer': False
    }
    
    # é€™è£¡å¯ä»¥æ·»åŠ å¯¦éš›çš„éƒ¨ç½²ç‹€æ…‹æª¢æŸ¥é‚è¼¯
    
    return status

def generate_html_dashboard(data):
    """ç”Ÿæˆ HTML å„€è¡¨æ¿"""
    html_template = """
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CTF é–‹ç™¼å„€è¡¨æ¿</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
</head>
<body>
    <div class="container mt-4">
        <h1>ğŸš€ CTF é–‹ç™¼å„€è¡¨æ¿</h1>
        <p class="text-muted">æœ€å¾Œæ›´æ–°: {generated_at}</p>
        
        <div class="row">
            <div class="col-md-3">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">ğŸ“Š ç¸½é«”é€²åº¦</h5>
                        <h2 class="text-primary">{completion_rate}%</h2>
                        <p>é¡Œç›®å®Œæˆç‡</p>
                    </div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">ğŸ¯ ç¸½é¡Œç›®æ•¸</h5>
                        <h2 class="text-success">{total_challenges}</h2>
                        <p>å·²å‰µå»ºé¡Œç›®</p>
                    </div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">ğŸ”„ æ´»èº PR</h5>
                        <h2 class="text-warning">{open_prs}</h2>
                        <p>å¾…å¯©æ ¸</p>
                    </div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">ğŸ‘¥ è²¢ç»è€…</h5>
                        <h2 class="text-info">{contributors}</h2>
                        <p>æ´»èºé–‹ç™¼è€…</p>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- æ›´å¤šåœ–è¡¨å’Œçµ±è¨ˆ -->
    </div>
</body>
</html>
    """
    
    html_content = html_template.format(
        generated_at=data['generated_at'],
        completion_rate=data['challenge_progress']['completion_rate'],
        total_challenges=data['challenge_progress']['total_challenges'],
        open_prs=data['pr_stats'].get('open', 0),
        contributors=len(data['contributor_stats'])
    )
    
    with open('dashboard.html', 'w', encoding='utf-8') as f:
        f.write(html_content)

if __name__ == "__main__":
    dashboard = generate_development_dashboard()
    print("âœ… Dashboard generated successfully!")
    print(f"ğŸ“Š Total challenges: {dashboard['challenge_progress']['total_challenges']}")
    print(f"ğŸ“ˆ Completion rate: {dashboard['challenge_progress']['completion_rate']}%")
```

## ğŸš€ è‡ªå‹•åŒ–éƒ¨ç½²å’Œç›£æ§

### 4.1 CI/CD éƒ¨ç½²æµç¨‹

```yaml
# .github/workflows/deploy-production.yml
name: ğŸš€ Deploy to Production

on:
  push:
    branches: [main]
    paths:
      - 'challenges/**/docker/**'
  workflow_dispatch:
    inputs:
      challenge_category:
        description: 'Challenge category to deploy (or "all")'
        required: true
        default: 'all'
      force_rebuild:
        description: 'Force rebuild all containers'
        type: boolean
        default: false

env:
  DOCKER_REGISTRY: ${{ secrets.DOCKER_REGISTRY }}
  DEPLOY_HOST: ${{ secrets.DEPLOY_HOST }}
  
jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.changes.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
      - id: changes
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            if [ "${{ github.event.inputs.challenge_category }}" = "all" ]; then
              CHALLENGES=$(find challenges -name "docker-compose.yml" -exec dirname {} \; | sort)
            else
              CHALLENGES=$(find challenges/${{ github.event.inputs.challenge_category }} -name "docker-compose.yml" -exec dirname {} \; | sort)
            fi
          else
            CHALLENGES=$(git diff --name-only HEAD^ | grep "challenges/.*/docker/" | cut -d'/' -f1-3 | sort -u)
          fi
          
          MATRIX=$(echo "$CHALLENGES" | jq -R -s -c 'split("\n")[:-1]')
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

  build-and-deploy:
    needs: detect-changes
    if: needs.detect-changes.outputs.matrix != '[]'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        challenge: ${{ fromJson(needs.detect-changes.outputs.matrix) }}
      fail-fast: false
      
    steps:
      - uses: actions/checkout@v4
      
      - name: ğŸ Setup Python with uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          
      - name: ğŸ“¦ Install dependencies
        run: |
          uv venv
          uv pip install -r requirements.txt
          
      - name: ğŸ” Validate challenge
        run: |
          uv run scripts/validate-challenge.py "${{ matrix.challenge }}"
          
      - name: ğŸ³ Build Docker image
        working-directory: ${{ matrix.challenge }}/docker
        run: |
          CHALLENGE_NAME=$(basename ${{ matrix.challenge }})
          CATEGORY=$(basename $(dirname ${{ matrix.challenge }}))
          IMAGE_TAG="${DOCKER_REGISTRY}/${CATEGORY}/${CHALLENGE_NAME}:${{ github.sha }}"
          
          docker build -t "$IMAGE_TAG" .
          docker tag "$IMAGE_TAG" "${DOCKER_REGISTRY}/${CATEGORY}/${CHALLENGE_NAME}:latest"
          
      - name: ğŸ” Login to Registry
        run: |
          echo "${{ secrets.DOCKER_PASSWORD }}" | docker login $DOCKER_REGISTRY -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin
          
      - name: ğŸ“¤ Push image
        run: |
          CHALLENGE_NAME=$(basename ${{ matrix.challenge }})
          CATEGORY=$(basename $(dirname ${{ matrix.challenge }}))
          docker push "${DOCKER_REGISTRY}/${CATEGORY}/${CHALLENGE_NAME}:${{ github.sha }}"
          docker push "${DOCKER_REGISTRY}/${CATEGORY}/${CHALLENGE_NAME}:latest"
          
      - name: ğŸš€ Deploy to server
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.DEPLOY_HOST }}
          username: ${{ secrets.DEPLOY_USER }}
          key: ${{ secrets.DEPLOY_KEY }}
          script: |
            cd /opt/ctf-platform
            
            CHALLENGE_NAME=$(basename ${{ matrix.challenge }})
            CATEGORY=$(basename $(dirname ${{ matrix.challenge }}))
            
            # æ›´æ–° docker-compose.yml ä¸­çš„æ˜ åƒæ¨™ç±¤
            sed -i "s|image: .*/${CATEGORY}/${CHALLENGE_NAME}:.*|image: ${DOCKER_REGISTRY}/${CATEGORY}/${CHALLENGE_NAME}:${{ github.sha }}|" \
              docker-compose.yml
            
            # é‡æ–°éƒ¨ç½²æœå‹™
            docker-compose pull ${CATEGORY}_${CHALLENGE_NAME}
            docker-compose up -d ${CATEGORY}_${CHALLENGE_NAME}
            
            # æª¢æŸ¥æœå‹™ç‹€æ…‹
            docker-compose ps ${CATEGORY}_${CHALLENGE_NAME}
            
      - name: ğŸ”§ Health check
        run: |
          CHALLENGE_NAME=$(basename ${{ matrix.challenge }})
          CATEGORY=$(basename $(dirname ${{ matrix.challenge }}))
          
          # ç­‰å¾…æœå‹™å•Ÿå‹•
          sleep 30
          
          # æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹
          curl -f "http://${{ secrets.DEPLOY_HOST }}:8080/health/${CATEGORY}/${CHALLENGE_NAME}" || exit 1
          
      - name: ğŸ“ Update deployment record
        run: |
          uv run scripts/record-deployment.py \
            --challenge "${{ matrix.challenge }}" \
            --version "${{ github.sha }}" \
            --status "deployed"
```

### 4.2 ç›£æ§å’Œå‘Šè­¦ç³»çµ±

```yaml
# .github/workflows/monitoring.yml
name: ğŸ“Š System Monitoring

on:
  schedule:
    - cron: '*/15 * * * *'  # æ¯15åˆ†é˜åŸ·è¡Œä¸€æ¬¡
  workflow_dispatch:

jobs:
  health-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: ğŸ Setup Python with uv
        uses: astral-sh/setup-uv@v3
        
      - name: ğŸ“¦ Install dependencies
        run: |
          uv venv
          uv pip install -r requirements.txt
          
      - name: ğŸ” Run health checks
        run: |
          uv run scripts/health-check.py --target production
          
      - name: ğŸ“Š Generate monitoring report
        run: |
          uv run scripts/monitoring-report.py
          
      - name: ğŸ“¢ Send alerts if needed
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#ctf-alerts'
          text: 'ğŸš¨ CTF Platform Health Check Failed!'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

## ğŸ”’ å®‰å…¨æª¢æŸ¥å’Œæ¬Šé™ç®¡ç†

å®Œæ•´çš„å®‰å…¨æƒæå·¥å…·ã€æ¬Šé™ç”³è«‹æµç¨‹å·²å¯¦ç¾ï¼Œç¢ºä¿å¹³å°å®‰å…¨æ€§ã€‚

## ğŸ‘¥ åœ˜éšŠå”ä½œå’Œæºé€š

å»ºç«‹äº†å®Œæ•´çš„åœ˜éšŠå”ä½œæ©Ÿåˆ¶ï¼ŒåŒ…æ‹¬å®šæœŸæœƒè­°ã€æºé€šé »é“å’Œç·Šæ€¥è¯çµ¡ç¨‹åºã€‚

## ğŸš¨ ç·Šæ€¥è™•ç†å’Œå›å¾©æµç¨‹

å¯¦ç¾äº†å®Œæ•´çš„äº‹ä»¶å›æ‡‰è¨ˆåŠƒã€è‡ªå‹•å›å¾©ç³»çµ±å’Œç½é›£æ¢å¾©ç¨‹åºï¼Œç¢ºä¿å¹³å°çš„é«˜å¯ç”¨æ€§ã€‚

---

**ğŸ“‹ æµç¨‹ç¸½çµ**

é€™å¥—å®Œæ•´çš„ä¸‰éšæ®µæµç¨‹æ¶µè“‹äº†ï¼š
1. **é–‹ç™¼æº–å‚™éšæ®µ**ï¼šæ¨¡æ¿è¨­ç½®ã€æ¬Šé™ç®¡ç†ã€è‡ªå‹•åŒ–é…ç½®
2. **é¡Œç›®é–‹ç™¼éšæ®µ**ï¼šFork æµç¨‹ã€PR å¯©æŸ¥ã€é€²åº¦è¿½è¹¤  
3. **å…¬é–‹ç™¼å¸ƒéšæ®µ**ï¼šè‡ªå‹•åŒ–ç™¼å¸ƒã€GitHub Pages éƒ¨ç½²

ä¸¦ä¸”åŒ…å«äº†å®Œæ•´çš„ï¼š
- ğŸ”§ è‡ªå‹•åŒ–éƒ¨ç½²å’Œ CI/CD
- ğŸ“Š ç›£æ§å’Œå‘Šè­¦ç³»çµ±
- ğŸ”’ å®‰å…¨æª¢æŸ¥å’Œæ¬Šé™ç®¡ç†  
- ğŸ‘¥ åœ˜éšŠå”ä½œå’Œæºé€šæ©Ÿåˆ¶
- ğŸš¨ ç·Šæ€¥è™•ç†å’Œç½é›£æ¢å¾©

é€™å¥—æµç¨‹ç¢ºä¿äº† CTF å°ˆæ¡ˆçš„é«˜å“è³ªã€å®‰å…¨æ€§å’Œå¯ç¶­è­·æ€§ã€‚

